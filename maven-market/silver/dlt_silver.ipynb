{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bed4ea5-2984-4ee5-b213-f12bafe1dbe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Calenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "624a575e-bfde-4810-b4a0-b68361f62ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, quarter, dayofmonth, to_date, trim\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.calenders_silver\",\n",
    "    comment=\"Conformed calendar dimension\"\n",
    ")\n",
    "#@dlt.expect_or_drop(\"valid_date\", \"date IS NOT NULL\")\n",
    "def calenders():\n",
    "    df = dlt.read(\"maven_uc.bronze_dlt.calenders\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"date\", to_date(trim(col(\"date\")), \"M/d/yyyy\"))\n",
    "        .withColumn(\"day\", dayofmonth(col(\"date\")))\n",
    "        .withColumn(\"month\", month(col(\"date\")))\n",
    "        .withColumn(\"quarter\", quarter(col(\"date\")))\n",
    "        .withColumn(\"year\", year(col(\"date\")))\n",
    "        .select(\"date\", \"day\", \"month\", \"quarter\", \"year\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92297620-1f1b-4742-a5a2-478b54e94713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Inventory events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b93d8f3-d852-4b97-ac4e-6a1c82478ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.inventory_events_silver\",\n",
    "    comment=\"Inventory restock events\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_product\", \"product_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_store\", \"store_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_qty\", \"restock_qty >= 0\")\n",
    "def inventory_events():\n",
    "    df = dlt.read_stream(\"maven_uc.bronze_dlt.inventory_streaming_table\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"restock_date\", to_date(col(\"restock_date\"), \"M/d/yyyy\"))\n",
    "        .select(\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            \"restock_qty\",\n",
    "            \"quantity_remaining\",\n",
    "            \"restock_date\",\n",
    "            \"event_ts\",\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d399edf-9cdc-4eb7-8e17-eedbfa855b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Order Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dafe0aa-c81e-4462-b5dd-497f7ca645a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.orders_events_silver\",\n",
    "    comment=\"Cleaned order events from Kafka\"\n",
    ")\n",
    "#@dlt.expect_or_drop(\"valid_qty\", \"quantity > 0\")\n",
    "#@dlt.expect(\"valid_price\", \"unit_price >= 0\")\n",
    "def orders_events_silver():\n",
    "    df = dlt.read_stream(\"maven_uc.bronze_dlt.orders_streaming_table\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"order_date\", to_date(col(\"order_date\"), \"M/d/yyyy\"))\n",
    "        .withColumn(\"stock_date\", to_date(col(\"stock_date\"), \"M/d/yyyy\"))\n",
    "        .select(\n",
    "            \"order_id\",\n",
    "            \"customer_id\",\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            col(\"order_date\").cast(\"date\"),\n",
    "            col(\"quantity\").cast(\"int\"),\n",
    "            col(\"stock_date\").cast(\"date\"),\n",
    "            col(\"payment_type\"),\n",
    "            col(\"price\").cast(\"decimal(12,2)\").alias(\"unit_price\"),\n",
    "            col(\"order_ts\").cast(\"timestamp\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c70887-d03b-43a7-a4ec-b573b02d56cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0749407a-8716-4e4e-83ae-56cacd2ce93b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.customers_silver\",\n",
    "    comment=\"Current customer snapshot\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_customer_id\", \"customer_id IS NOT NULL\")\n",
    "def customers():\n",
    "    df = dlt.read(\"mongo_customers\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"homeowner\", col(\"homeowner\") == \"Yes\")\n",
    "        .withColumn(\"member_card\", col(\"member_card\") == \"Yes\")\n",
    "        .withColumn(\"ingestion_ts\", current_timestamp())\n",
    "        .withColumn(\"birthdate\", to_date(col(\"birthdate\"), \"M/d/yyy\"))\n",
    "        .withColumn(\"acct_open_date\", to_date(col(\"acct_open_date\"), \"M/d/yyy\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97199134-8e80-445c-aa0f-7c32652a1aba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa7d9c5b-5cc8-4f58-866d-a1b70a53a2d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.products_silver\",\n",
    "    comment=\"Cleaned and standardized product snapshot\"\n",
    ")\n",
    "@dlt.expect_or_drop(\n",
    "    \"valid_product_id\",\n",
    "    \"product_id IS NOT NULL\"\n",
    ")\n",
    "def products_silver():\n",
    "    return (\n",
    "        dlt.read(\"mongo_products\")\n",
    "        .select(\n",
    "            \"product_id\",\n",
    "            col(\"product_brand\"),\n",
    "            col(\"product_name\"),\n",
    "            col(\"product_sku\").cast(\"bigint\"),\n",
    "            col(\"product_retail_price\").cast(\"double\"),\n",
    "            col(\"product_cost\").cast(\"double\"),\n",
    "            col(\"product_weight\").cast(\"double\"),\n",
    "            # :white_check_mark: semantic fixes\n",
    "            (col(\"low_fat\") == 1).alias(\"low_fat\"),\n",
    "            (col(\"recyclable\") == 1).alias(\"recyclable\"),\n",
    "            col(\"ingestion_ts\"),\n",
    "            col(\"source_system\")\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999a810b-9947-4af5-a22e-7e226c6bfae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03eb3404-c242-47f5-9b01-58d2d6555390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.regions_silver\",\n",
    "    comment=\"Sales regions dimension\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_region_id\", \"region_id IS NOT NULL\")\n",
    "def regions():\n",
    "    df = dlt.read(\"maven_uc.bronze_dlt.regions\")\n",
    "    return (\n",
    "        df\n",
    "        .select(\n",
    "            \"region_id\",\n",
    "            \"sales_region\",\n",
    "            \"sales_district\",\n",
    "            \"ingestion_timestamp\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "680c1038-4ffd-476d-8f47-58acc8433ab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d02d2d5-f3f7-4665-ab14-88632fa0ed34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## DLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ec81bdb-5f66-4c42-9af9-1c8230426fe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.returns_silver\",\n",
    "    comment=\"Cleaned product returns\"\n",
    ")\n",
    "@dlt.expect(\"valid_return_date\", \"return_date IS NOT NULL\")\n",
    "@dlt.expect(\"valid_quantity\", \"quantity IS NOT NULL AND CAST(quantity AS INT) > 0\")\n",
    "def returns():\n",
    "    df = dlt.read(\"maven_uc.bronze_dlt.returns\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"return_date\", to_date(col(\"return_date\"), \"M/d/yyy\"))\n",
    "        .withColumn(\"quantity\", col(\"quantity\").cast(IntegerType()))\n",
    "        .withColumnRenamed(\"ingestion_timestamp\", \"created_at\")\n",
    "        .select(\n",
    "            \"return_date\",\n",
    "            \"product_id\",\n",
    "            \"store_id\",\n",
    "            \"quantity\",\n",
    "        )\n",
    "    )\n",
    "# The error was caused by renaming 'quantity' to 'return_quantity' before the .select(), \n",
    "# which made 'quantity' unavailable for the @dlt.expect and .select(). \n",
    "# The fix is to keep the column name as 'quantity'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb149e2c-62d7-4ed0-9da0-680d2730a63a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8433a3cc-a8e9-48a0-a950-dc127e28db56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## For DLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b908a62-9544-4bd7-ab27-7e3a1cbe428e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, to_date, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.stores_silver\",\n",
    "    comment=\"Clean store dimension\"\n",
    ")\n",
    "@dlt.expect(\"valid_store_id\", \"store_id IS NOT NULL\")\n",
    "@dlt.expect(\n",
    "    \"valid_sqft\",\n",
    "    \"\"\"\n",
    "    (total_sqft IS NULL OR CAST(total_sqft AS INT) >= 0)\n",
    "    AND\n",
    "    (grocery_sqft IS NULL OR CAST(grocery_sqft AS INT) >= 0)\n",
    "    \"\"\"\n",
    ")\n",
    "def stores():\n",
    "    df = dlt.read(\"maven_uc.bronze_dlt.stores\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"first_opened_date\", to_date(trim(col(\"first_opened_date\")), \"M/d/yyy\"))\n",
    "        .withColumn(\"last_remodel_date\", to_date(trim(col(\"last_remodel_date\")), \"M/d/yyy\"))\n",
    "        .withColumn(\"total_sqft\", col(\"total_sqft\").cast(IntegerType()))\n",
    "        .withColumn(\"grocery_sqft\", col(\"grocery_sqft\").cast(IntegerType()))\n",
    "        .select(\n",
    "            \"store_id\",\n",
    "            \"region_id\",\n",
    "            \"store_type\",\n",
    "            \"store_name\",\n",
    "            \"store_street_address\",\n",
    "            \"store_city\",\n",
    "            \"store_state\",\n",
    "            \"store_country\",\n",
    "            \"store_phone\",\n",
    "            \"first_opened_date\",\n",
    "            \"last_remodel_date\",\n",
    "            \"total_sqft\",\n",
    "            \"grocery_sqft\",\n",
    "            #\"created_at\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f53e803-9d51-4964-9af6-c19967143968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a4e11db-7f09-4778-9cd0-602577c6db9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "719e855c-f603-461b-9eb2-3526bbaf9a61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, to_date, trim\n",
    "from pyspark.sql.types import IntegerType\n",
    "@dlt.table(\n",
    "    name=\"maven_uc.silver_dlt.transactions_silver\",\n",
    "    comment=\"Cleaned transaction facts\"\n",
    ")\n",
    "@dlt.expect(\"valid_transaction_date\", \"transaction_date IS NOT NULL\")\n",
    "@dlt.expect(\"valid_quantity\", \"quantity IS NOT NULL AND CAST(quantity AS INT) > 0\")\n",
    "def transactions():\n",
    "    df = dlt.read(\"maven_uc.bronze_dlt.transactions\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"transaction_date\", to_date(trim(col(\"transaction_date\")), \"M/d/yyy\"))\n",
    "        .withColumn(\"stock_date\", to_date(trim(col(\"stock_date\")), \"M/d/yyy\"))\n",
    "\n",
    "        .withColumn(\"quantity\", col(\"quantity\").cast(IntegerType()))\n",
    "        .withColumnRenamed(\"ingestion_timestamp\", \"created_at\")\n",
    "        .select(\n",
    "            \"transaction_date\",\n",
    "            \"stock_date\",\n",
    "            \"product_id\",\n",
    "            \"customer_id\",\n",
    "            \"store_id\",\n",
    "            \"quantity\",\n",
    "            #\"created_at\"\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
