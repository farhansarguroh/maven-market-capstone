{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a37051c-f2be-4e89-81a5-5d9e3d18c802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "kafka_bootstrap_servers = \"pkc-oxqxx9.us-east-1.aws.confluent.cloud:9092\"\n",
    "kafka_api_key = \"GDYCUMDX5QRPX2WS\"\n",
    "kafka_api_secret = \"cflt9HN3ZSyS33B342mEmdOWwfm6tYShkf6sBnUwi44G6ZjASGQ8eVBfkqeRPyTQ\"\n",
    "\n",
    "orders_topic = \"orders_stream\"\n",
    "inventory_topic = \"inventory_stream\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2aa589-b9f4-4664-a34a-50b4877beec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a2762bb-bc2f-48c5-9bdc-fbbcfdb44448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", StringType()),\n",
    "    StructField(\"customer_id\", StringType()),\n",
    "    StructField(\"product_id\", StringType()),\n",
    "    StructField(\"store_id\", StringType()),\n",
    "    StructField(\"order_date\", StringType()),\n",
    "    StructField(\"quantity\", IntegerType()),\n",
    "    StructField(\"stock_date\", StringType()),\n",
    "    StructField(\"payment_type\", StringType()),\n",
    "    StructField(\"price\", DoubleType()),\n",
    "    StructField(\"order_ts\", TimestampType())\n",
    "])\n",
    "\n",
    "@dp.table(\n",
    "    name=\"orders_streaming_table\",\n",
    "    comment=\"Streaming table ingesting orders from Kafka\"\n",
    ")\n",
    "def orders_streaming_table():\n",
    "    df_kafka = (\n",
    "        spark.readStream\n",
    "        .format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"subscribe\", orders_topic)\n",
    "        .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "        .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "        .option(\n",
    "            \"kafka.sasl.jaas.config\",\n",
    "            f\"kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username='{kafka_api_key}' password='{kafka_api_secret}';\"\n",
    "        )\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .load()\n",
    "    )\n",
    "    return (\n",
    "        df_kafka\n",
    "        .selectExpr(\"CAST(value AS STRING) as value\")\n",
    "        .select(from_json(col(\"value\"), orders_schema).alias(\"data\"))\n",
    "        .select(\"data.*\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faefb385-56fd-4d93-a179-fd552fc437c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "# Databricks no-op command",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "COUNTER"
         },
         {
          "key": "options",
          "value": {
           "counterColName": "Total_orders",
           "counterLabel": "Real Time",
           "rowNumber": 1,
           "stringDecChar": ".",
           "stringDecimal": 0,
           "stringThouSep": ",",
           "targetRowNumber": 1,
           "tooltipFormat": "0,0.000"
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "155b1eea-8808-43bb-9893-c1c7390413f3",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# 1. Create a streaming DataFrame by reading the table as a stream\n",
    "streaming_df = (spark.readStream\n",
    "                .table(\"maven_uc.bronze_dlt.orders_streaming_table\"))\n",
    "\n",
    "# 2. Perform the aggregation\n",
    "total_orders_df = streaming_df.select(count(\"order_id\").alias(\"Total_orders\"))\n",
    "\n",
    "# 3. Display the live output in the notebook\n",
    "display(total_orders_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c207d62c-810c-4fd3-93b7-3d2cc266cb9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72abce10-e4c9-400a-80ae-992afaaf8a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "inventory_schema = StructType([\n",
    "    StructField(\"product_id\", StringType()),\n",
    "    StructField(\"store_id\", StringType()),\n",
    "    StructField(\"restock_qty\", IntegerType()),\n",
    "    StructField(\"quantity_remaining\", IntegerType()),\n",
    "    StructField(\"restock_date\", StringType()),\n",
    "    StructField(\"event_ts\", TimestampType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a323950c-9489-4580-8be8-26c3030a6840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "@dp.table(\n",
    "    name=\"inventory_streaming_table\",\n",
    "    comment=\"Streaming table ingesting inventory from Kafka\"\n",
    ")\n",
    "def inventory_streaming_table():\n",
    "    df_kafka = (\n",
    "        spark.readStream\n",
    "        .format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"subscribe\", inventory_topic)\n",
    "        .option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "        .option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "        .option(\n",
    "            \"kafka.sasl.jaas.config\",\n",
    "            f\"kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username='{kafka_api_key}' password='{kafka_api_secret}';\"\n",
    "        )\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .load()\n",
    "    )\n",
    "    return (\n",
    "        df_kafka\n",
    "        .selectExpr(\"CAST(value AS STRING) as value\")\n",
    "        .select(from_json(col(\"value\"), inventory_schema).alias(\"data\"))\n",
    "        .select(\"data.*\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": null,
       "elementNUID": "155b1eea-8808-43bb-9893-c1c7390413f3",
       "elementType": "command",
       "guid": "5c2cea31-671a-446f-8510-9557222d613f",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "4f404461-7c81-4689-b75b-56670079f724",
     "origId": 177015150812310,
     "title": "REALLLLLLLLLLLLLLLLL",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "kafka_topic",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
